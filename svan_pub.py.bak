#!/usr/bin/env python3
"""
author: archieyoung<yangqi2@grandomics.com>
SVAN: A Struture Variation Annotation Tool
"""
import sys
import os
import subprocess
import operator
import argparse
import logging


import sv_vcf
import dbPrepare

def table_check(table):
    """
    check if the table have consistent field number of each row
    return field number of the table
    """
    with open(table,"r") as io:
        # skip comment lines
        check_momment_line = io.readline()
        while check_momment_line[0] == "#":
            # comment lines start with "#"
            check_momment_line = io.readline()
            pass
        first_record_line = check_momment_line # first record line
        first_record_field_num = len(first_record_line.split("\t"))
        lines = io.readlines()
        for line in lines:
            field_num = len(line.split("\t"))
            if field_num != first_record_field_num:
                raise RuntimeError("field number not consistent: "
                        "first record field num is {}, but {} "
                        "field num is {}".format(first_record_field_num,
                            field_num,line))
    return first_record_field_num

# db fields "chrom","start","end","svtype","annot1","annot2","annot3"...
# format: "annot1;annot1","annot2,annot2";"annot3;annot3","chrom:start-end,svtype;..."
# if multiple result is founded in database, write each feature in one column,
# and seperate by semicolon
def format_result(result):
    for i in result:
        variations = []
        #init annotations
        annotations = [[] for p in range(len(result[i][0])-4)]
        for j in result[i]:
            variations.append("{}:{}-{},{}".format(j[0],j[1],j[2],j[3]))
            for k in range(len(annotations)):
                annotations[k].append(j[k+4])
        variations_str = ";".join(variations)
        annotations_str = [";".join(l) for l in annotations]
        result[i] = annotations_str+[variations_str]
    return result


def range_compare(bedtools,bedA,bedB,min_overlap,tmp_dir,prefix,db_id):
    # result sv dict, key: query sv id, value: db fields
    intersect_result = {}

    # calculate query and database fields number
    query_field_num = table_check(bedA)
    # db_field_num = table_check(bedB)

    range_intersect_tmp_bed = os.path.join(tmp_dir
            ,prefix+"."+db_id+".intersect.tmp.bed")

    if min_overlap > 0:
        with open(range_intersect_tmp_bed,"w") as io:
            subprocess.run([bedtools,"intersect","-a",bedA,"-b",bedB,"-loj",
                "-f",str(min_overlap),"-r"],stdout=io)
    else:
        with open(range_intersect_tmp_bed,"w") as io:
            subprocess.run([bedtools,"intersect","-a",bedA,"-b",bedB,"-loj"],
                    stdout=io)
    # read intersect file
    # bedA query bed
    # chrom start end svtype svid svlen re info;
    # svid is a unique identifier for the sv
    query_field_names = ["chrom","start","end","svtype","svid"] # main field names
    db_field_names = ["chrom","start","end","svtype"] # main field names
    with open(range_intersect_tmp_bed,"r") as io:
        lines = io.readlines()
        for line in lines:
            fields = line.strip().split("\t")
            query_fields = fields[:query_field_num]
            db_fields = fields[query_field_num:]
            query_dict = {}
            for i in range(5):
                query_dict[query_field_names[i]] = query_fields[i]
            db_dict = {}
            for j in range(4):
                db_dict[db_field_names[j]] = db_fields[j]
            if (query_dict["svtype"] == "DEL" and (db_dict["svtype"] == "DEL"
                or db_dict["svtype"] == "CNV")): # DEL match DEL or CNV
                intersect_result.setdefault(query_dict["svid"],
                        []).append(db_fields)
            if (query_dict["svtype"] == "DUP" and (db_dict["svtype"] == "DUP"
                or db_dict["svtype"] == "CNV" or db_dict["svtype"] == "INS")): # DUP match DUP or CNV or INS
                intersect_result.setdefault(query_dict["svid"],
                        []).append(db_fields)
            if query_dict["svtype"] == "INV" and db_dict["svtype"] == "INV": # INV match INV
                intersect_result.setdefault(query_dict["svid"],
                        []).append(db_fields)
            # WILD database SV type matchs any query SV type
            if db_dict["svtype"] == "WILD":
                intersect_result.setdefault(query_dict["svid"],
                        []).append(db_fields)
    return format_result(intersect_result)


def ins_compare(bedtools,bedA,bedB,max_dist,tmp_dir,prefix,db_id):
    # result sv dict, key: query sv id, value: db fields
    ins_compare_result = {}

    # calculate query and database fields number
    query_field_num = table_check(bedA)
    # db_field_num = table_check(bedB)

    ins_compare_tmp_bed = os.path.join(tmp_dir
            ,prefix+"."+db_id+".ins_compare.tmp.bed")

    with open(ins_compare_tmp_bed,"w") as io:
        subprocess.run([bedtools,"closest","-D","ref","-t","first",
            "-a",bedA,"-b",bedB],stdout=io)

    # read closest file
    # bedA query bed
    # chrom start end svtype svid svlen re info;
    # svid is a unique identifier for the sv
    query_field_names = ["chrom","start","end","svtype","svid"] # main field names
    db_field_names = ["chrom","start","end","svtype"] # main field names
    with open(ins_compare_tmp_bed,"r") as io:
        lines = io.readlines()
        for line in lines:
            fields = line.strip().split("\t")
            query_fields = fields[:query_field_num]
            db_fields = fields[query_field_num:-1] # last column is dist
            query_dict = {}
            for i in range(5):
                query_dict[query_field_names[i]] = query_fields[i]
            db_dict = {}
            for j in range(4):
                db_dict[db_field_names[j]] = db_fields[j]
            # dist must less or equal to max_dist
            dist = abs(int(fields[-1]))
            if dist > max_dist:
                continue
            # INS matchs INS or DUP or CNV
            if (query_dict["svtype"] == "INS" and (db_dict["svtype"] == "INS"
                or db_dict["svtype"] == "DUP" or db_dict["svtype"] == "CNV")):
                ins_compare_result.setdefault(query_dict["svid"],
                    []).append(db_fields)
            # WILD database SV type matchs any query SV type
            if db_dict["svtype"] == "WILD":
                ins_compare_result.setdefault(query_dict["svid"],
                    []).append(db_fields)
    return format_result(ins_compare_result)


def tra_compare(bedtools, bedA, bedB, max_dist, tmp_dir,
        prefix, db_id):
    # result sv dict, key: query sv id, value: db fields
    tra_compare_result = []

    # calculate query and database fields number
    query_field_num = table_check(bedA)
    # db_field_num = table_check(bedB)

    tra_compare_tmp_bed = os.path.join(tmp_dir,
            prefix+"."+db_id+".tra_compare.tmp.bed")

    with open(tra_compare_tmp_bed, "w") as io:
        subprocess.run([bedtools, "closest", "-D", "ref", "-t", "first",
            "-a",bedA,"-b",bedB],stdout=io)

    # read closest file
    # bedA query bed
    # chrom start end svtype svid svlen re info;
    # svid is a unique identifier for the sv
    # query_field_names = ["chrom","start","end","svtype","svid"] # main field names
    # db_field_names = query_field_names # main field names
    tra_paired = {} # get translocation position pair from bed

    with open(tra_compare_tmp_bed, "r") as io:
        lines = io.readlines()
        for line in lines:
            fields = line.strip().split("\t")
            query_svid = fields[4]
            db_fields = fields[query_field_num:-1]
            db_svtype = db_fields[3]
            # match WILD database SV type, WILD is used for annotate HI only
            if db_svtype == "WILD":
                tra_compare_result.setdefault(query_svid, []).append(db_fields)
            else:
                tra_main_id = "_".join(query_svid.split("_")[:-1])
                tra_paired.setdefault(tra_main_id,[]).append(fields)

    if tra_paired:
        for i in tra_paired:
            if not len(tra_paired[i]) == 2:
                continue # not paired, missing one of breakpoint of the tra

            if (abs(tra_paired[i][0][-1]) < max_dist and
                    abs(tra_paired[i][1][-1]) < max_dist):

                pos1_query_fields = tra_paired[i][0][:query_field_num]
                pos1_db_fields = tra_paired[i][0][query_field_num:-1]
                pos2_query_fields = tra_paired[i][1][:query_field_num]
                pos2_db_fields = tra_paired[i][1][query_field_num:-1]

                pos1_db_sv_type = pos1_db_fields[3]
                pos2_db_sv_type = pos2_db_fields[3]

                if pos1_db_sv_type != "TRA" or pos2_db_sv_type != "TRA":
                    continue # TRA match TRA only

                pos1_db_sv_main_id = "_".join(pos1_db_fields[4].split("_")[:-1])
                pos2_db_sv_main_id = "_".join(pos2_db_fields[4].split("_")[:-1])

                if pos1_db_sv_main_id == pos2_db_sv_main_id:
                    pos1_query_id = pos1_query_fields[4]
                    pos2_query_id = pos2_query_fields[4]
                    tra_compare_result.setdefault(pos1_query_id,
                            []).append(pos1_db_fields)
                    tra_compare_result.setdefault(pos2_query_id,
                            []).append(pos2_db_fields)
    return format_result(tra_compare_result)



def queryPrepare_vcf(tmp, prefix, vcf_in, bed_out):
    """
    Convert VCF to BED
    Remove query chrom "chr" prefix if it exists, because database SV
    chrom do not have "chr" prefix.
    Sort bed file by "chrom" and "start", the same as "sort -k1,1 -k2,2n"
    """
    bed_tmp1 = os.path.join(tmp, prefix+".query.bed.tmp1")
    # vcf to bed
    sv_vcf.vcf_to_bed(vcf_in,bed_tmp1)
    # sort bed
    bed_list = []
    query_list = []
    with open(bed_tmp1, "r") as io:
        for line in io:
            line = line.strip()
            fields = line.split("\t")
            query_list.append(line)
            # Remove query chrom "chr" prefix if it exists
            fields[0] = fields[0].replace("chr","")
            fields[1] = int(fields[1])
            bed_list.append(fields)
    bed_list.sort(key = operator.itemgetter(0, 1))
    with open(bed_out, "w") as io:
        for i in bed_list:
            i[1] = str(i[1])
            io.write("\t".join(i)+"\n")
    return query_list


def queryPrepare_bed(tmp, prefix, bed_in, bed_out):
    """
    Remove query chrom "chr" prefix if it exists, because database SV
    chrom do not have "chr" prefix.
    Sort bed file by "chrom" and "start", the same as "sort -k1,1 -k2,2n"
    """
    # sort bed
    bed_list = []
    query_list = []
    with open(bed_in, "r") as io:
        for line in io:
            line = line.strip()
            fields = line.split("\t")
            query_list.append(line)
            # Remove query chrom "chr" prefix if it exists
            fields[0] = fields[0].replace("chr","")
            fields[1] = int(fields[1])
            bed_list.append(fields)
    bed_list.sort(key = operator.itemgetter(0, 1))
    with open(bed_out, "w") as io:
        for i in bed_list:
            i[1] = str(i[1])
            io.write("\t".join(i)+"\n")
    return query_list


def table_maker(query_list,*db_result): # db_result: (db, [header])
    header = ["Chr","Start","End","SVTPE","SVID","SVLEN","RE","INFO"]
    for j,k in db_result:
        header.extend(k)
    table = {}
    for i in query_list:
        fields = i.split("\t")
        svid = fields[4]
        for j,k in db_result:
            if svid in j:
                table.setdefault(svid,fields).extend(j[svid])
            else:
                table.setdefault(svid,fields).extend(["." for l in k])
    return header,table


def get_args():
    parser = argparse.ArgumentParser(
            description="SVAN: Structure variation annotation",
            usage="usage: %(prog)s [options]")
    parser.add_argument("--vcf",
        help="vcf file [default %(default)s]", metavar="FILE")
    parser.add_argument("--bed",
        help="bed file [default %(default)s]", metavar="FILE")
    parser.add_argument("--dbdir",
        help="database directory [default %(default)s]", metavar="DIR")
    parser.add_argument("--min_overlap",
        help="minimum reciprocal overlap fraction for \"Range\" SV A and"
        " \"Rang\" SV B [default %(default)s]",type=float,default=0.5,metavar="FLOAT")
    parser.add_argument("--max_dist",
        help="maximum distance for \"Point\" SV A and"
        " \"Point\" SV B [default %(default)s]",type=int,default=1000,metavar="FLOAT")
    parser.add_argument("--prefix",
        help="output file name [default %(default)s]", metavar="STR")
    parser.add_argument("--tmp",
        help="temporary directory [default %(default)s]",
        default="tmp",metavar="DIR")
    if len(sys.argv) <= 1:
        parser.print_help()
        exit()
    return parser.parse_args()


def main():

    args = get_args()

    if not os.path.exists(args.tmp):
        os.mkdir(args.tmp)

    logging.basicConfig(format='%(asctime)s:%(levelname)s:%(message)s',
            level=logging.INFO)

    # prepare query sv
    bed_query = os.path.join(args.tmp,args.prefix+".query.bed")
    if args.vcf: # vcf query
        query_list = queryPrepare_vcf(args.tmp,args.prefix,args.vcf,bed_query)
    else: # bed query
        query_list = queryPrepare_bed(args.tmp,args.prefix,args.bed,bed_query)

    logging.info("Preparing SV database")
    # prepare database SV
    # raw SV files
    one_thousand_sv_raw = os.path.join(args.dbdir,
            "ALL.wgs.integrated_sv_map_v2.20130502.svs.genotypes.1000genome.vcf.gz")
    dgv_raw = os.path.join(args.dbdir,
            "DGV.GS.March2016.50percent.GainLossSep.Final.hg19.gff3")
    dbVar_raw = os.path.join(args.dbdir,
            "nstd37.GRCh37.variant_call.vcf.gz")
    decipher_hi_raw = os.path.join(args.dbdir,
            "decipher_HI_Predictions_Version3.bed.gz")

    for i in [one_thousand_sv_raw,dgv_raw,dbVar_raw,decipher_hi_raw]:
        if not os.path.exists(i):
            raise RuntimeError("Error: {} was not founded!".format(i))

    one_thousand_sv_db = os.path.join(args.tmp,
            "ALL.wgs.integrated_sv_map_v2.20130502.svs.genotypes.1000genome.db.bed")
    dgv_db = os.path.join(args.tmp,
            "DGV.GS.March2016.50percent.GainLossSep.Final.hg19.db.bed")
    dbVar_db = os.path.join(args.tmp,
            "nstd37.GRCh37.variant_call.db.bed")
    decipher_hi_db = os.path.join(args.tmp,
            "decipher_HI_Predictions_Version3.db.bed")

    dbPrepare.one_thousand_sv.print_bed(one_thousand_sv_raw,one_thousand_sv_db)
    dbPrepare.dgv_gold_cnv.print_bed(dgv_raw,dgv_db)
    dbPrepare.dbVar_nstd37_sv.print_bed(dbVar_raw,dbVar_db)
    dbPrepare.decipher_HI.print_bed(decipher_hi_raw,decipher_hi_db)

    logging.info("Annotating DEL,DUP and INV")
    bedtools = "bedtools"
    # a loop needed here
    # 1000g
    one_thousand_sv_intersect_result = range_compare(bedtools,bed_query,
            one_thousand_sv_db,args.min_overlap,args.tmp,args.prefix,"1000g")
    # dgv
    dgv_intersect_result = range_compare(bedtools,bed_query,dgv_db,
            args.min_overlap,args.tmp,args.prefix,"dgv")
    # dbVar
    dbVar_intersect_result = range_compare(bedtools,bed_query,dbVar_db,
            args.min_overlap,args.tmp,args.prefix,"dbVar")

    # decipher HI, set args.min_overlap to 0
    decipher_HI_intersect_result = range_compare(bedtools,bed_query,decipher_hi_db,
            0,args.tmp,args.prefix,"decipher_hi")

    logging.info("Getting INS from query SVs")
    bed_query_ins_list = []
    with open(bed_query,"r") as io:
        for line in io:
            fields = line.strip().split("\t")
            if fields[3] == "INS":
                bed_query_ins_list.append(line)
    # tmp query insertion file name
    bed_query_ins = os.path.join(args.tmp,args.prefix+".query_INS.tmp.bed")
    with open(bed_query_ins,"w") as io:
        io.writelines(bed_query_ins_list)

    logging.info("Annotating INS")
    # a loop needed here
    # 1000g
    one_thousand_sv_ins_compare_result = ins_compare(bedtools,bed_query_ins,
            one_thousand_sv_db,args.max_dist,args.tmp,args.prefix,"1000g")
    # dgv
    dgv_ins_compare_result = ins_compare(bedtools,bed_query_ins,
            dgv_db,args.max_dist,args.tmp,args.prefix,"dgv")
    # dbVar
    dbVar_ins_compare_result = ins_compare(bedtools,bed_query_ins,
            dbVar_db,args.max_dist,args.tmp,args.prefix,"dbVar")

    # decipher HI, set args.max_dist to 0
    decipher_HI_ins_compare_result = ins_compare(bedtools,bed_query_ins,
            decipher_hi_db,0,args.tmp,args.prefix,"decipher_hi")

    one_thousand_sv_intersect_result.update(one_thousand_sv_ins_compare_result)
    dgv_intersect_result.update(dgv_ins_compare_result)
    dbVar_intersect_result.update(dbVar_ins_compare_result)
    decipher_HI_intersect_result.update(decipher_HI_ins_compare_result)

    #print result
    one_thousand_result = (one_thousand_sv_intersect_result,["1000g_subtype",
        "1000g_AF","1000g_EAS_AF","1000g_EUR_AF","1000g_AFR_AF","1000g_AMR_AF",
        "1000g_SAS_AF","1000g_sv"])
    dgv_result = (dgv_intersect_result,["dgv_AF","dgv_sample_size","dgv_sv"])
    dbVar_result = (dbVar_intersect_result,["dbVar_CLNSIG","dbVar_PHENO","dbVar_sv"])
    decipher_HI_result = (decipher_HI_intersect_result, ["Decipher_HI","Decipher_range"])
    header,table = table_maker(query_list,one_thousand_result,dgv_result,
            dbVar_result,decipher_HI_result)
    with open(args.prefix+".svannot.tsv","w") as io:
        io.write("#"+"\t".join(header)+"\n")
        lines = ["\t".join(table[i])+"\n" for i in table]
        io.writelines(lines)

if __name__ == "__main__":
    main()

